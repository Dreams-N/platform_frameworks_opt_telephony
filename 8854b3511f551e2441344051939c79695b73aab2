Revision: 8854b3511f551e2441344051939c79695b73aab2
Patch-set: 6
File: src/java/com/android/internal/telephony/RIL.java

159
Wed Feb 27 06:02:01 2013 +0000
Author: YING WEI <1013953@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: QPkfXMLU
Bytes: 255
Is it possible to keep 0 as initial serial? As we can use it to count how many requests have been sent out after RILD socked connected. Also this is called when RILD socket disconnected. Why we would mix old requests with new?  What problem did you meet ?

159
Thu Mar 07 23:27:05 2013 +0000
Author: Robert Greenwalt <1002609@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: QPkfXMLU
UUID: RJKGuGLs
Bytes: 340
The problem this is trying to fix is ensuring after a recovery we probably won't mis-interpret responses - that the serial numbers of the new commands will be substantially different from those in the old responses.  We could have the first generation start at 0 if you want - I don't think the recovery mechanism gets exercised very often.

159
Tue Mar 12 05:52:39 2013 +0000
Author: YING WEI <1013953@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: RJKGuGLs
UUID: RiPpkKfw
Bytes: 315
We will resetSerial when RILD socket disconnected.
If RILD socked disconnected, clearRequestsList() will clear all requests when socked disconnected. When RILD socket connected again, new serial number will start from 0, while no old requests. So I think there will no mis-interpret case.
Correct me if  I am wrong.

159
Tue Mar 12 18:24:20 2013 +0000
Author: Robert Greenwalt <1002609@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: RiPpkKfw
UUID: Rf3cDuMw
Bytes: 684
We would prefer to keep this.  It is possible for the RILD and radio code to pass the sequence number through into radio state as the request is being acted on - the RILD may notice the socket error and re-establish the connection and then the response comes back from the radio with the old sequence number and get's passed back through the newly-connected RILD.

Just because your implementation may not do this, we can imagine other OEMs passing back obsolete responses that would match a newly-zero'd RIL sequence number and confuse things.

Couldn't you just remember the first sequence number your RILD connection received?  Then you know the number of requests you've received.

239
Wed Feb 27 06:02:01 2013 +0000
Author: YING WEI <1013953@85c56323-6fa9-3386-8a01-6480fb634889>
UUID: QPgfhOI8
Bytes: 586
It is great that you decrease three locks (mWakelock, pending, mRequestList) to 1 lock(mRequestList). From code perspective, it is more simple. And I can not find current drain issue in current fix.

While one lock may have thread efficiency issue.
eg, 
receive thread is in findAndRemoveRequestFromList(),
switch to main thread acquireWakeLock, as mRequestList is held by receive thread, main thread will be blocked.

Actually there are two resources(mRequestList / mRequestMessagesOutstanding), as one lock protect one resource. Is it possible to keep two locks for the two resources?

239
Thu Mar 07 23:27:05 2013 +0000
Author: Robert Greenwalt <1002609@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: QPgfhOI8
UUID: RJAE0rE4
Bytes: 520
Both the sending thread and the response processing thread access the wakelock, the count and the list.  We could break it into two separate wakelocks and in most places it would be ok - though the timeout and clearRequestList code would need nested locks (not a good thing).  The question is does the potential performance increase warrant the potential deadlock (if somebody in the future grabs the locks in the wrong order).

I can get greater perf increases just optimizing what we've got.  Let me take another pass.

239
Tue Mar 12 05:52:39 2013 +0000
Author: YING WEI <1013953@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: RJAE0rE4
UUID: RiLrhESM
Bytes: 570
You are correct that there are three objects(the wakelock, the count and the list).
I think we can separate them into two parts (the wakelock and the count) and (the list). As the count operation will always be with wakelock. 
In main thread, we will not handle list. As we do not need to wait for the list lock, which receive/send thread hold. I think this is what we can optimize.
While send/receive thread might hold both list lock and wakelock lock. This might be potential deadlock.
So we should ensure each thread do not hold one lock and waiting for another lock.

239
Tue Mar 12 18:24:20 2013 +0000
Author: Robert Greenwalt <1002609@85c56323-6fa9-3386-8a01-6480fb634889>
Parent: RiLrhESM
UUID: Rf8wM44I
Bytes: 904
Which thread for you is the "main thread"?  The response listener, the handler or the random send callers?  I assume not the random callers: that's multiple threads.

The RILReceiver is accessing both the list (to match up responses with requests) and the wakelock/count.

The handler is adding to the list and in an error may need to decrement the wakelock count.  In a timeout it definitely needs to do both.

There are two places where we need to synchronously hold both list lock and wakelock/count lock:  Timeouts (due to debug output) and clearRequestList.  We can nest the locks in those two places so there's no deadlock, but it introduces the risk of future changes causing rare and hard-to-diagnose deadlocks.

We are not convinced that this channel is busy enough and has contention enough to warrant the risk of this optimization.  Do you have data on the amount of contention in this module?

